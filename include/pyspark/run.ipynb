{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b006305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. è‡ªåŠ¨å¤„ç†è·¯å¾„ä¸ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "current_path = os.getcwd()\n",
    "if current_path not in sys.path:\n",
    "    sys.path.append(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23debc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preloaded GX Suite: reddit_posts_bz_suite\n"
     ]
    }
   ],
   "source": [
    "from spark_common import MinIOSparkManager\n",
    "from setup import LakehouseSetupManager\n",
    "from bronze import Bronze\n",
    "from silver import Silver\n",
    "from gold import Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "once = True \n",
    "processing_time = \"5 seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96873f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åˆå§‹åŒ– Manager\n",
    "manager = MinIOSparkManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea46dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/luhui/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/luhui/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-699c023b-736f-4d87-8d4a-a1a0eaefbc30;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.1 in central\n",
      "\tfound io.delta#delta-storage;3.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 84ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-699c023b-736f-4d87-8d4a-a1a0eaefbc30\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/2ms)\n",
      "26/01/08 13:46:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# 2. å¯åŠ¨ Spark\n",
    "spark = manager.create_session(\"Reddit_ETL_Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 4. åˆå§‹åŒ– Setup Manager (ç¯å¢ƒæ³¨å…¥)\n",
    "    # ç»Ÿä¸€ä½¿ç”¨ manager å·²ç»ä» .env ä¸­è§£æå¥½çš„é…ç½®ï¼Œæ¶ˆé™¤ localhost/minio çš„å†²çª\n",
    "    DBsetup = LakehouseSetupManager(\n",
    "        spark_session=spark,\n",
    "        endpoint=manager.endpoint,\n",
    "        access_key=manager.access_key,\n",
    "        secret_key=manager.secret_key,\n",
    "        bucket=manager.bucket\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸš€ å¼€å§‹å…¨é“¾è·¯ ETL æµç¨‹ (Mode: {'Batch' if once else 'Streaming'})\")\n",
    "    print(f\"ğŸ“ ç›®æ ‡å­˜å‚¨: {manager.endpoint} / {manager.bucket}\")\n",
    "\n",
    "    # --- é˜¶æ®µ 1: Bronze (Raw -> Delta) ---\n",
    "    print(\"\\nğŸ“¦ [STAGE: BRONZE] æ­£åœ¨åŒæ­¥æ•°æ®è‡³åŸå§‹å±‚...\")\n",
    "    bronze = Bronze(spark, DBsetup)\n",
    "    bronze.consume(once, processing_time)\n",
    "\n",
    "    # --- é˜¶æ®µ 2: Silver (Filter & Cast -> Delta) ---\n",
    "    print(\"\\nğŸ¥ˆ [STAGE: SILVER] æ­£åœ¨æ¸…æ´—å¹¶è½¬æ¢è‡³ç™½é“¶å±‚...\")\n",
    "    silver = Silver(spark, DBsetup)\n",
    "    silver.upsert(once, processing_time)\n",
    "\n",
    "    # --- é˜¶æ®µ 3: Gold (CDC & Deduplication -> Delta) ---\n",
    "    print(\"\\nğŸ¥‡ [STAGE: GOLD] æ­£åœ¨èšåˆå¹¶å»é‡è‡³é»„é‡‘å±‚...\")\n",
    "    gold = Gold(spark, DBsetup)\n",
    "    gold.upsert(once, processing_time)\n",
    "\n",
    "    print(\"\\nâœ¨ æ‰€æœ‰å±‚çº§å¤„ç†å®Œæˆï¼\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    # 5. ç¡®ä¿ Spark èµ„æºè¢«é‡Šæ”¾\n",
    "    print(\"ğŸ›‘ æ­£åœ¨å…³é—­ Spark Session...\")\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
