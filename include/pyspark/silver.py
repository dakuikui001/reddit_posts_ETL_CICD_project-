import os
import time
from pathlib import Path
from pyspark.sql import functions as F
from pyspark.sql.window import Window

class Upserter:
    def __init__(self, merge_query, temp_view_name):
        self.merge_query = merge_query
        self.temp_view_name = temp_view_name

    def upsert(self, df_micro_batch, batch_id):
        # --- å…³é”®ï¼šå¾®æ‰¹æ¬¡å†…å»é‡ ---
        # å¦‚æœåŒä¸€ä¸ª post_id åœ¨ä¸€æ¬¡æŠ“å–ä¸­å‡ºç°äº†å¤šæ¬¡ï¼ŒMERGE ä¼šæŠ¥é”™
        # æˆ‘ä»¬åªå–æœ€æ–°çš„é‚£ä¸€æ¡è®°å½•è¿›è¡Œåˆå¹¶
        window_spec = Window.partitionBy("post_id").orderBy(F.col("extracted_time").desc())
        df_deduplicated = (df_micro_batch
            .withColumn("rn", F.row_number().over(window_spec))
            .filter("rn = 1")
            .drop("rn")
        )
        
        df_deduplicated.createOrReplaceTempView(self.temp_view_name)
        df_deduplicated._jdf.sparkSession().sql(self.merge_query)

class Silver():
    def __init__(self, spark_session, db_setup_manager):
        self.spark = spark_session
        self.manager = db_setup_manager 
        self.db_name = "reddit_db"
        self.checkpoint_base = f"s3a://{self.manager.bucket}/_checkpoints/silver"
        print(f"ğŸ’¾ Silver å±‚ Checkpoint æ ¹è·¯å¾„: {self.checkpoint_base}")
 
    def upsert_reddit_posts_sl(self, once=True, processing_time="15 seconds", startingVersion=0):
        # è·å–è¡¨è·¯å¾„
        reddit_posts_bz = self.manager._get_table_location("reddit_posts_bz", "s3a")
        reddit_posts_sl = self.manager._get_table_location("reddit_posts_sl", "s3a")

        # --- ä¼˜åŒ–åçš„ MERGE é€»è¾‘ ---
        # åªæœ‰åœ¨å…³é”®æŒ‡æ ‡å˜åŒ–æ—¶æ‰æ‰§è¡Œæ›´æ–°æ“ä½œï¼Œå‡å°‘æ— æ•ˆå†™å…¥
        query = f"""
            MERGE INTO delta.`{reddit_posts_sl}` a
            USING reddit_posts_sl_delta b
            ON a.post_id = b.post_id
            WHEN MATCHED AND (
                a.score != b.score OR 
                a.comments != b.comments OR 
                a.upvote_ratio != b.upvote_ratio
            ) THEN UPDATE SET *
            WHEN NOT MATCHED THEN INSERT *
        """
        data_upserter = Upserter(query, "reddit_posts_sl_delta")

        # è¯»å–æµ
        df_delta = (self.spark.readStream
            .option("startingVersion", startingVersion)
            .option("ignoreDeletes", True)
            .format("delta")
            .load(reddit_posts_bz)
            # æ•°æ®æ¸…æ´—ä¸è½¬æ¢
            .withColumn("is_video", F.col("is_video").cast('boolean'))
            .withColumn("is_self", F.col("is_self").cast('boolean'))
            .withColumn("created_utc", F.to_timestamp(F.col("created_utc"), "yyyy-MM-dd HH:mm:ss"))
            .withColumn("update_time", F.current_timestamp())
        )

        return self._write_stream_update(
            df_delta, 
            data_upserter, 
            "reddit_posts_sl", 
            "reddit_posts_sl_upsert_stream", 
            "silver_p1", 
            once, 
            processing_time
        )

    def _write_stream_update(self, df, upserter, path, query_name, pool, once, processing_time):
        checkpoint_path = f"{self.checkpoint_base}/{path}"
        
        stream_writer = (df.writeStream
            .foreachBatch(upserter.upsert)
            .outputMode("update")
            .option("checkpointLocation", checkpoint_path)
            .queryName(query_name)
        )
        
        self.spark.sparkContext.setLocalProperty("spark.scheduler.pool", pool)
        
        if once:
            return stream_writer.trigger(availableNow=True).start()
        else:
            return stream_writer.trigger(processingTime=processing_time).start()
    
    def _await_queries(self, once):
        if once:
            for stream in self.spark.streams.active:
                stream.awaitTermination()
    
    def upsert(self, once=True, processing_time="5 seconds"):
        start = int(time.time())
        print(f"\nğŸš€ å¯åŠ¨ Silver å±‚ CDC Upsert...")

        # è¿è¡Œ Upsert ä»»åŠ¡
        self.upsert_reddit_posts_sl(once, processing_time)
        
        # ç­‰å¾…æµç»“æŸ
        self._await_queries(once)
        print(f"âœ… Silver å±‚æ›´æ–°å®Œæˆï¼Œè€—æ—¶: {int(time.time()) - start} ç§’")